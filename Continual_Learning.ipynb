{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODdPYFeNzApnW7axtsCRHz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isaac-Gregory/Continual-Learning-Project/blob/data_aug/Continual_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continual Learning Demonstration\n",
        "\n",
        "CSCE 5280 - AI for Healthcare and Wearables\n",
        "\n",
        "Professor: Dr. Mark Albert  \n",
        "\n",
        "TA: Mr. Riyad Bin Rafiq\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Students working on the project:\n",
        "\n",
        "Fahmid Shahriar Iqbal,\n",
        "Gayaetiri Chalasani,\n",
        "Isaac Gregory,\n",
        "Joseph Caldwell"
      ],
      "metadata": {
        "id": "v1nD2kz5iTDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "# import torchvision.transforms as transforms\n",
        "from torchvision.transforms import v2\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "zwGD5j52qAWa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "7P9wBayDr6qT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gathering Images and Labels"
      ],
      "metadata": {
        "id": "nLxV2ZrmDVOE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMZz69UPhsqX",
        "outputId": "328775fe-0fdd-4660-907d-85aa557f7124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_train/asl_alphabet_train\n"
          ]
        }
      ],
      "source": [
        "# Downloading data (NOTE: There are no issues if data is already downloaded)\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\") + \"/asl_alphabet_train/asl_alphabet_train\"\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating folder setup for loading into PyTorch later..."
      ],
      "metadata": {
        "id": "3_c4IyYBpZn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating each task's directories\n",
        "task1_dirs = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
        "task2_dirs = [\"I\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\"]\n",
        "task3_dirs = [\"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\"]\n",
        "\n",
        "# Creating new directories in path for different tasks\n",
        "# (This helps in loading to pytorch later)\n",
        "if not os.path.exists(path + \"/task1\"):\n",
        "  os.mkdir(path + \"/task1\")\n",
        "  os.mkdir(path + \"/task2\")\n",
        "  os.mkdir(path + \"/task3\")\n",
        "\n",
        "  # Moving directories into respective tasks\n",
        "  for dir in task1_dirs:\n",
        "    os.rename(path + \"/\" + dir, path + \"/task1/\" + dir)\n",
        "  for dir in task2_dirs:\n",
        "    os.rename(path + \"/\" + dir, path + \"/task2/\" + dir)\n",
        "  for dir in task3_dirs:\n",
        "    os.rename(path + \"/\" + dir, path + \"/task3/\" + dir)"
      ],
      "metadata": {
        "id": "KAtx6ECLoEHZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing file paths and labels into dataframe...\n",
        "\n",
        "(NOTE: this may prove to be unnecessary now)"
      ],
      "metadata": {
        "id": "ApWA-xGUpdlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task1_list = []\n",
        "task2_list = []\n",
        "task3_list = []\n",
        "\n",
        "# Walking through folders\n",
        "for dir, _, files in os.walk(path):\n",
        "  for filename in files:\n",
        "\n",
        "    # Printing labels and photos\n",
        "    # print(dirname[-1], filename)\n",
        "\n",
        "    # Gathering data into dataframes\n",
        "    # (each letter except J and Z due to movement)\n",
        "    if dir[-1] in task1_dirs:\n",
        "      task1_list.append((os.path.join(dir, filename), dir[-1]))\n",
        "    elif dir[-1] in task2_dirs:\n",
        "      task2_list.append((os.path.join(dir, filename), dir[-1]))\n",
        "    elif dir[-1] in task3_dirs:\n",
        "      task3_list.append((os.path.join(dir, filename), dir[-1]))\n",
        "\n",
        "task1 = pd.DataFrame(task1_list, columns=['file_path', 'target'])\n",
        "task2 = pd.DataFrame(task2_list, columns=['file_path', 'target'])\n",
        "task3 = pd.DataFrame(task3_list, columns=['file_path', 'target'])"
      ],
      "metadata": {
        "id": "U3ZFjCgUi7QN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the data..."
      ],
      "metadata": {
        "id": "vJZLYOz58--D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(task1['target']), task1.shape)\n",
        "print(np.unique(task2['target']), task2.shape)\n",
        "print(np.unique(task3['target']), task3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-C0DUeS4Ziy",
        "outputId": "1ce26ef4-7dfa-41ba-b75a-92e0d0735292"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H'] (24000, 2)\n",
            "['I' 'K' 'L' 'M' 'N' 'O' 'P' 'Q'] (24000, 2)\n",
            "['R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y'] (24000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1.head()"
      ],
      "metadata": {
        "id": "8aFoLbAi8xMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task2.head()"
      ],
      "metadata": {
        "id": "_KA4eXVG_za6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task3.head()"
      ],
      "metadata": {
        "id": "oPtvwCq9_1Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(task1.groupby('target').count())\n",
        "print(task2.groupby('target').count())\n",
        "print(task3.groupby('target').count())"
      ],
      "metadata": {
        "id": "H9BtSXG-DN5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "eiK82ca4DbMW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UbeTPXKWFWlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "-LzI4wGADLxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NPvVDKjFV2a",
        "outputId": "42ecfe47-0dd8-4598-e6c2-edab872eb156"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ac41db3ee50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate mean and std\n",
        "# vals = [[],[],[]]\n",
        "# mean = []\n",
        "# std = []\n",
        "# temp_dataset = datasets.ImageFolder(path + \"/task1\", transform=transforms.ToTensor())\n",
        "# for images, _ in temp_dataset:\n",
        "#     for j in range(3):  # Assuming 3 channels (RGB)\n",
        "#         channel = images[j, :, :]\n",
        "#         vals[j].append(channel)\n",
        "\n",
        "# for i in range(3):\n",
        "#     # vals[i] = torch.stack(vals[i])\n",
        "#     mean.append(np.mean(vals[i]))\n",
        "#     std.append(np.std(vals[i]))"
      ],
      "metadata": {
        "id": "VjADyq61Ya9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(mean)\n",
        "# print(std)"
      ],
      "metadata": {
        "id": "1cmrmBY0jKBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating image transformations/augmentations\n",
        "transforms = v2.Compose([\n",
        "    v2.RandomResizedCrop(size=(200, 200), antialias=True),\n",
        "    v2.RandomRotation(degrees=90, expand=False),\n",
        "    v2.ColorJitter(),\n",
        "    v2.GaussianBlur(),\n",
        "    v2.Normalize(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "8o2GK9z4YcyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(path, transform=transforms)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "ebpUWCOwRUc3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}